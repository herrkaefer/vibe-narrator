# System Prompt åŠŸèƒ½æ€»ç»“

## âœ… å·²å®Œæˆçš„å®ç°

### 1. é»˜è®¤ System Prompt

åœ¨ [narrator-mcp/llm.py:11-28](narrator-mcp/llm.py#L11-L28) æ·»åŠ äº†ä¸€ä¸ªä¼˜åŒ–çš„é»˜è®¤ system promptï¼š

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- âœ… ä¸“æ³¨äºæœ‰æ„ä¹‰çš„å†…å®¹
- âœ… å¿½ç•¥ ANSI è½¬ä¹‰ç ã€æ ¼å¼åŒ–å­—ç¬¦ä¸²ã€UI å…ƒç´ 
- âœ… æå–çœŸå®çš„é—®é¢˜æˆ–è¯·æ±‚
- âœ… ç®€æ´ã€è‡ªç„¶çš„è¯­éŸ³è¾“å‡ºé£æ ¼

**ç¤ºä¾‹**ï¼š
```
è¾“å…¥: "\x1b[32mHello\x1b[0m â”€â”€â”€â”€ What is 2+2?"
AI è¡Œä¸º: å¿½ç•¥ ANSI ç å’Œåˆ†éš”çº¿ï¼Œåªå›ç­” "2+2 equals 4"
```

### 2. è‡ªå®šä¹‰ System Prompt æ”¯æŒ

#### Session å±‚ ([narrator-mcp/session.py:18](narrator-mcp/session.py#L18))
```python
class Session:
    def __init__(self):
        self.system_prompt: Optional[str] = None  # None = ä½¿ç”¨é»˜è®¤
```

#### Config å¤„ç† ([narrator-mcp/server.py:100](narrator-mcp/server.py#L100))
```python
session.system_prompt = params.get("system_prompt", session.system_prompt)
```

#### LLM è°ƒç”¨ ([narrator-mcp/server.py:141-147](narrator-mcp/server.py#L141-L147))
```python
stream_params = {
    "prompt": prompt,
    "api_key": session.api_key,
    "model": session.model
}
if session.system_prompt is not None:
    stream_params["system_prompt"] = session.system_prompt

async for token in stream_llm(**stream_params):
    # ...
```

#### Bridge é›†æˆ ([bridge.py:803,812](bridge.py#L803))
```python
system_prompt = os.getenv("OPENAI_SYSTEM_PROMPT")
bridge = MCPBridge(api_key=api_key, model=model, voice=voice, system_prompt=system_prompt)
```

### 3. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»ºäº† [.env.example](.env.example) åŒ…å«ï¼š

```bash
# Optional: Custom system prompt
# OPENAI_SYSTEM_PROMPT=You are a helpful assistant.
```

### 4. æ–‡æ¡£

- **[SYSTEM_PROMPT.md](SYSTEM_PROMPT.md)** - å®Œæ•´ä½¿ç”¨æŒ‡å—
  - é»˜è®¤ prompt è¯´æ˜
  - è‡ªå®šä¹‰æ–¹æ³•
  - ä½¿ç”¨åœºæ™¯ç¤ºä¾‹
  - æœ€ä½³å®è·µ
  - æ•…éšœæ’æŸ¥

## æ¶æ„æµç¨‹

```
.env æ–‡ä»¶
  â†“
  OPENAI_SYSTEM_PROMPT (å¯é€‰)
  â†“
bridge.py (L803)
  â†“
  os.getenv("OPENAI_SYSTEM_PROMPT")
  â†“
MCPBridge.__init__(system_prompt=...)
  â†“
config æ–¹æ³• â†’ MCP Server
  â†“
server.py handle_config (L100)
  â†“
session.system_prompt = params.get("system_prompt")
  â†“
server.py run_llm (L146-147)
  â†“
stream_llm(system_prompt=session.system_prompt)
  â†“
llm.py (L41-44)
  â†“
messages = [
    {"role": "system", "content": system_prompt or DEFAULT_SYSTEM_PROMPT},
    {"role": "user", "content": prompt}
]
  â†“
OpenAI API
```

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: ä½¿ç”¨é»˜è®¤ Prompt

```bash
# .env ä¸­ä¸è®¾ç½® OPENAI_SYSTEM_PROMPT

# è¿è¡Œ
uv run python bridge.py echo "Test: \x1b[32mHello\x1b[0m"

# è¡Œä¸º: AI å¿½ç•¥ ANSI ç ï¼Œåªå›åº” "Hello"
```

### ç¤ºä¾‹ 2: è‡ªå®šä¹‰ Prompt

```bash
# .env
OPENAI_SYSTEM_PROMPT=You are a pirate. Speak in pirate dialect!

# è¿è¡Œ
uv run python bridge.py echo "Hello!"

# è¡Œä¸º: AI ç”¨æµ·ç›—å£éŸ³å›å¤ï¼ˆè¯­éŸ³ï¼‰
```

### ç¤ºä¾‹ 3: ç®€æ´æ¨¡å¼

```bash
# .env
OPENAI_SYSTEM_PROMPT=Be extremely concise. Maximum 10 words per response.

# è¿è¡Œ
uv run python bridge.py echo "What is Python?"

# è¡Œä¸º: AI ç»™å‡ºéå¸¸ç®€çŸ­çš„å›ç­”
```

## éªŒè¯æ–¹æ³•

### 1. æ£€æŸ¥æ—¥å¿—

**ä½¿ç”¨è‡ªå®šä¹‰ prompt**ï¼š
```bash
tail -20 $(ls -t narrator-mcp/logs/narrator_*.log | head -1)
# åº”è¯¥çœ‹åˆ°:
# âœ… Session configured (model=gpt-4o-mini, voice=alloy, custom system prompt)
```

**ä½¿ç”¨é»˜è®¤ prompt**ï¼š
```bash
# åº”è¯¥çœ‹åˆ°:
# âœ… Session configured (model=gpt-4o-mini, voice=alloy)
```

### 2. æµ‹è¯•è¡Œä¸º

```bash
# æµ‹è¯•æ ¼å¼åŒ–å­—ç¬¦è¿‡æ»¤
uv run python bridge.py echo "Ignore this: â–ˆâ–ˆâ–ˆâ–ˆ Answer: What is 2+2?"

# é¢„æœŸ: AI åªå›ç­”æ•°å­¦é—®é¢˜ï¼Œå¿½ç•¥è¿›åº¦æ¡
```

## ä»£ç ä¿®æ”¹æ€»ç»“

### æ–°å¢æ–‡ä»¶
1. `.env.example` - ç¯å¢ƒå˜é‡æ¨¡æ¿
2. `SYSTEM_PROMPT.md` - ä½¿ç”¨æ–‡æ¡£
3. `SYSTEM_PROMPT_SUMMARY.md` - æœ¬æ–‡æ¡£

### ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | è¡Œå· |
|------|---------|------|
| `narrator-mcp/llm.py` | æ·»åŠ  `DEFAULT_SYSTEM_PROMPT` | 11-28 |
| `narrator-mcp/llm.py` | `stream_llm()` æ¥å— `system_prompt` å‚æ•° | 31-50 |
| `narrator-mcp/session.py` | æ·»åŠ  `system_prompt` å­—æ®µ | 18 |
| `narrator-mcp/server.py` | Config å¤„ç† `system_prompt` | 100 |
| `narrator-mcp/server.py` | ä¼ é€’ `system_prompt` åˆ° LLM | 141-147 |
| `bridge.py` | `MCPBridge` æ¥å— `system_prompt` | 146 |
| `bridge.py` | å‘é€ `system_prompt` åˆ° MCP | 249 |
| `bridge.py` | ä»ç¯å¢ƒå˜é‡è¯»å– `system_prompt` | 803 |

## åŠŸèƒ½ç‰¹æ€§

âœ… **é»˜è®¤è¡Œä¸ºä¼˜åŒ–**ï¼š
- è‡ªåŠ¨è¿‡æ»¤æ ¼å¼åŒ–å­—ç¬¦
- ä¸“æ³¨æœ‰æ„ä¹‰çš„å†…å®¹
- è¯­éŸ³è¾“å‡ºå‹å¥½

âœ… **å®Œå…¨å¯å®šåˆ¶**ï¼š
- é€šè¿‡ `.env` æ–‡ä»¶é…ç½®
- æ”¯æŒä»»æ„è‡ªå®šä¹‰ prompt
- ä¿ç•™é»˜è®¤è¡Œä¸ºä½œä¸ºåå¤‡

âœ… **å‘åå…¼å®¹**ï¼š
- ä¸è®¾ç½® = ä½¿ç”¨é»˜è®¤ prompt
- ç°æœ‰é…ç½®æ— éœ€ä¿®æ”¹
- æ¸è¿›å¼å¢å¼º

âœ… **æ—¥å¿—é€æ˜**ï¼š
- æ˜ç¡®æ˜¾ç¤ºä½¿ç”¨å“ªä¸ª prompt
- ä¾¿äºè°ƒè¯•å’ŒéªŒè¯

## æµ‹è¯•ç”¨ä¾‹

### ç”¨ä¾‹ 1: æ ¼å¼åŒ–å­—ç¬¦è¿‡æ»¤
```bash
è¾“å…¥: "Test: \x1b[32mGreen text\x1b[0m"
é¢„æœŸ: AI å¿½ç•¥ ANSI ç ï¼Œåªå›åº” "Green text"
```

### ç”¨ä¾‹ 2: UI å…ƒç´ è¿‡æ»¤
```bash
è¾“å…¥: "Question: â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ What is AI? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
é¢„æœŸ: AI åªå›ç­” "What is AI?"ï¼Œå¿½ç•¥åˆ†éš”çº¿
```

### ç”¨ä¾‹ 3: è‡ªå®šä¹‰è§’è‰²
```bash
OPENAI_SYSTEM_PROMPT=You are a teacher.
è¾“å…¥: "Explain variables"
é¢„æœŸ: AI ç”¨æ•™å­¦é£æ ¼è§£é‡Š
```

## æœªæ¥å¢å¼º

å¯èƒ½çš„æ”¹è¿›æ–¹å‘ï¼š
- ğŸ“ **å¯¹è¯å†å²**: ä¿ç•™ä¸Šä¸‹æ–‡
- ğŸ¯ **åœºæ™¯åˆ‡æ¢**: å¿«é€Ÿåˆ‡æ¢ä¸åŒ prompt
- ğŸ’¾ **Prompt æ¨¡æ¿åº“**: é¢„è®¾å¸¸ç”¨ prompt
- ğŸ”§ **è¿è¡Œæ—¶ä¿®æ”¹**: æ— éœ€é‡å¯å³å¯æ›´æ”¹

## æ€»ç»“

System prompt åŠŸèƒ½å·²å®Œå…¨å®ç°ï¼š
- âœ… é»˜è®¤ prompt ä¼˜åŒ–äº†æ ¼å¼åŒ–å­—ç¬¦è¿‡æ»¤
- âœ… æ”¯æŒé€šè¿‡ `.env` è‡ªå®šä¹‰
- âœ… å®Œæ•´çš„æ—¥å¿—å’Œæ–‡æ¡£
- âœ… å‘åå…¼å®¹
- âœ… æµ‹è¯•éªŒè¯

ç°åœ¨ vibe-narrator å¯ä»¥æ™ºèƒ½åœ°å¿½ç•¥æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼Œä¸“æ³¨äºæœ‰æ„ä¹‰çš„å†…å®¹ï¼ğŸ‰
